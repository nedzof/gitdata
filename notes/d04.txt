
1) Update file: src/routes/ready.ts
With content:
```ts
import type { Request, Response, Router } from 'express';
import { Router as makeRouter } from 'express';
 //import { getDeclarationByVersion, getParents } from '../db';
import {
  loadHeaders,
  verifyEnvelopeAgainstHeaders,
  type HeadersIndex,
} from '../spv/verify-envelope';

const POLICY_MIN_CONFS = Number(process.env.POLICY_MIN_CONFS || 1);
const BUNDLE_MAX_DEPTH = Number(process.env.BUNDLE_MAX_DEPTH || 8);
const HEADERS_FILE = process.env.HEADERS_FILE || './data/headers.json';

let headersIdx: HeadersIndex | null = null;
function ensureHeaders(): HeadersIndex {
  if (!headersIdx) headersIdx = loadHeaders(HEADERS_FILE);
  return headersIdx!;
}

function json(res: Response, code: number, body: any) {
  return res.status(code).json(body);
}

/**
 * /ready
 * DFS over lineage (depth ≤ BUNDLE_MAX_DEPTH), verify SPV envelope for each node against current headers,
 * enforce min confirmations. No pinning — confirmations are computed live from headers.
 *
 * Response: { ready: boolean, reason?: string, confirmations?: number }
 * - confirmations (if present) is the minimum confirmations across all verified nodes at time of check.
 */
export function readyRouter(db: Database.Database): Router {
  const router = makeRouter();

  router.get('/ready', async (req: Request, res: Response) => {
    try {
      const versionId = String(req.query.versionId || '').toLowerCase();
      if (!/^[0-9a-fA-F]{64}$/.test(versionId)) {
        return json(res, 400, { ready: false, reason: 'bad-request' });
      }

      // Load headers snapshot once for this request
      let idx: HeadersIndex;
      try {
        idx = ensureHeaders();
      } catch (e: any) {
        return json(res, 200, { ready: false, reason: 'headers-unavailable' });
      }

      // DFS lineage
      const stack: Array<{ v: string; d: number }> = [{ v: versionId, d: 0 }];
      const seen = new Set<string>();
      let minConfsAcross = Number.POSITIVE_INFINITY;

      while (stack.length) {
        const { v, d } = stack.pop()!;
        if (seen.has(v)) continue;
        seen.add(v);

        const decl = getDeclarationByVersion(db, v);
        if (!decl?.proof_json) {
          return json(res, 200, { ready: false, reason: `missing-envelope:${v}` });
        }

        const env = JSON.parse(decl.proof_json);
        const vr = await verifyEnvelopeAgainstHeaders(env, idx, POLICY_MIN_CONFS);
        if (!vr.ok) {
          // Propagate reason; if insufficient confs, include computed confs
          return json(res, 200, {
            ready: false,
            reason: vr.reason,
            confirmations: vr.confirmations ?? 0,
          });
        }
        if (typeof vr.confirmations === 'number') {
          minConfsAcross = Math.min(minConfsAcross, vr.confirmations);
        }

        // Enqueue parents
        if (d < BUNDLE_MAX_DEPTH) {
          const parents = getParents(db, v);
          for (const p of parents) {
            if (!seen.has(p)) stack.push({ v: p, d: d + 1 });
          }
        }
      }

      // If lineage had no nodes (shouldn't happen), treat as not ready
      if (!seen.size) {
        return json(res, 200, { ready: false, reason: 'not-found' });
      }

      const confsOut = Number.isFinite(minConfsAcross) ? minConfsAcross : undefined;
      return json(res, 200, { ready: true, reason: null, confirmations: confsOut });
    } catch (e: any) {
      return json(res, 500, { ready: false, reason: String(e?.message || e) });
    }
  });

  return router;
}
```

2) Create file: test/integration/ready.spec.ts
With content:
```ts
import assert from 'assert';
import fs from 'fs';
import os from 'os';
import path from 'path';
import express from 'express';
import request from 'supertest';
 //
import { initSchema, upsertManifest, upsertDeclaration, replaceEdges } from '../../src/db';
import { readyRouter } from '../../src/routes/ready';
import { txidFromRawTx } from '../../src/spv/verify-envelope';

function rev(b: Buffer) { const c = Buffer.from(b); c.reverse(); return c; }
function sha256d(b: Buffer) {
  const crypto = require('crypto') as typeof import('crypto');
  const a = crypto.createHash('sha256').update(b).digest();
  return crypto.createHash('sha256').update(a).digest();
}

/** Build raw 80-byte header; return header hex + block hash (big-endian) */
function buildHeaderWithRoot(merkleRootBE: string): { headerHex: string; blockHash: string } {
  const versionLE = Buffer.alloc(4); versionLE.writeInt32LE(1, 0);
  const prevHashLE = Buffer.alloc(32);
  const merkleRootLE = rev(Buffer.from(merkleRootBE, 'hex'));
  const timeLE = Buffer.alloc(4); timeLE.writeUInt32LE(1700000000, 0);
  const bitsLE = Buffer.alloc(4); bitsLE.writeUInt32LE(0x1d00ffff, 0);
  const nonceLE = Buffer.alloc(4); nonceLE.writeUInt32LE(0x00000042, 0);
  const header = Buffer.concat([versionLE, prevHashLE, merkleRootLE, timeLE, bitsLE, nonceLE]);
  const blockHashBE = rev(sha256d(header)).toString('hex');
  return { headerHex: header.toString('hex'), blockHash: blockHashBE };
}

/** Create a minimal headers index file with two blocks at heights hParent and hChild */
function writeHeadersIndex(headersPath: string, records: Array<{ blockHash: string; merkleRoot: string; height: number }>, bestHeight: number, tipHash: string) {
  const byHash: any = {};
  for (const r of records) {
    byHash[r.blockHash.toLowerCase()] = {
      prevHash: '00'.repeat(32),
      merkleRoot: r.merkleRoot.toLowerCase(),
      height: r.height,
    };
  }
  fs.writeFileSync(headersPath, JSON.stringify({ bestHeight, tipHash, byHash }, null, 2));
}

(async function run() {
  // Prepare temp headers file
  const tmpDir = fs.mkdtempSync(path.join(os.tmpdir(), 'ready-'));
  const headersPath = path.join(tmpDir, 'headers.json');
  process.env.HEADERS_FILE = headersPath;

  // Express app with in-memory DB
  const app = express();
  app.use(express.json({ limit: '1mb' }));
  const db = new Database(':memory:');
  initSchema(db);
  app.use(readyRouter(db));

  // Build synthetic txids
  const rawTxChild = '00';
  const rawTxParent = '00';
  const txidChild = txidFromRawTx(rawTxChild);
  const txidParent = txidFromRawTx(rawTxParent);

  // Construct a simple two-leaf merkle root: root = sha256d(LE(txid) || LE(sibling))
  const sibling = Buffer.alloc(32, 0x11).toString('hex');
  const leafChildLE = rev(Buffer.from(txidChild, 'hex'));
  const leafParentLE = rev(Buffer.from(txidParent, 'hex'));
  const siblingLE = rev(Buffer.from(sibling, 'hex'));
  const rootChild = rev(sha256d(Buffer.concat([leafChildLE, siblingLE]))).toString('hex');
  const rootParent = rev(sha256d(Buffer.concat([leafParentLE, siblingLE]))).toString('hex');

  // Create two block headers
  const { blockHash: blockChild } = buildHeaderWithRoot(rootChild);
  const { blockHash: blockParent } = buildHeaderWithRoot(rootParent);

  // Headers: parent height 100, child height 101; tip is child; bestHeight 101
  writeHeadersIndex(headersPath, [
    { blockHash: blockParent, merkleRoot: rootParent, height: 100 },
    { blockHash: blockChild, merkleRoot: rootChild, height: 101 },
  ], 101, blockChild);

  // Manifests
  const vidParent = 'b'.repeat(64);
  const vidChild = 'a'.repeat(64);

  const manifestParent = {
    type: 'datasetVersionManifest',
    datasetId: 'ds-parent',
    content: { contentHash: 'c'.repeat(64) },
    provenance: { createdAt: '2024-05-01T00:00:00Z' },
    policy: { license: 'cc-by-4.0', classification: 'public' }
  };
  const manifestChild = {
    type: 'datasetVersionManifest',
    datasetId: 'ds-child',
    content: { contentHash: 'd'.repeat(64) },
    lineage: { parents: [vidParent] },
    provenance: { createdAt: '2024-05-02T00:00:00Z' },
    policy: { license: 'cc-by-4.0', classification: 'public' }
  };

  // DB insert minimal rows
  upsertManifest(db, {
    version_id: vidParent, manifest_hash: vidParent, content_hash: manifestParent.content.contentHash,
    title: null, license: 'cc-by-4.0', classification: 'public',
    created_at: manifestParent.provenance.createdAt, manifest_json: JSON.stringify(manifestParent)
  });
  upsertManifest(db, {
    version_id: vidChild, manifest_hash: vidChild, content_hash: manifestChild.content.contentHash,
    title: null, license: 'cc-by-4.0', classification: 'public',
    created_at: manifestChild.provenance.createdAt, manifest_json: JSON.stringify(manifestChild)
  });
  replaceEdges(db, vidChild, [vidParent]);

  // SPV envelopes (blockHash/height path for both)
  const envChild = {
    rawTx: rawTxChild,
    proof: { txid: txidChild, merkleRoot: rootChild, path: [{ hash: sibling, position: 'right' }] },
    block: { blockHash: blockChild, blockHeight: 101 },
  };
  const envParent = {
    rawTx: rawTxParent,
    proof: { txid: txidParent, merkleRoot: rootParent, path: [{ hash: sibling, position: 'right' }] },
    block: { blockHash: blockParent, blockHeight: 100 },
  };
  upsertDeclaration(db, { version_id: vidChild, txid: 'c'.repeat(64), type: 'DLM1', status: 'pending', created_at: Math.floor(Date.now()/1000), opret_vout: 0, raw_tx: rawTxChild, proof_json: JSON.stringify(envChild) } as any);
  upsertDeclaration(db, { version_id: vidParent, txid: 'p'.repeat(64), type: 'DLM1', status: 'pending', created_at: Math.floor(Date.now()/1000), opret_vout: 0, raw_tx: rawTxParent, proof_json: JSON.stringify(envParent) } as any);

  // 1) With minConfs = 1 (default), child has 1 conf, parent has 2 => ready true
  process.env.POLICY_MIN_CONFS = '1';
  const r1 = await request(app).get(`/ready?versionId=${vidChild}`);
  assert.strictEqual(r1.status, 200);
  assert.strictEqual(r1.body.ready, true);

  // 2) With minConfs = 2, child has only 1 => ready false with insufficient-confs
  process.env.POLICY_MIN_CONFS = '2';
  const r2 = await request(app).get(`/ready?versionId=${vidChild}`);
  assert.strictEqual(r2.status, 200);
  assert.strictEqual(r2.body.ready, false);
  assert.strictEqual(r2.body.reason, 'insufficient-confs');
  assert.strictEqual(typeof r2.body.confirmations, 'number');

  // 3) Reorg/height increase: bestHeight -> 102 makes child confs = 2 => ready true
  writeHeadersIndex(headersPath, [
    { blockHash: blockParent, merkleRoot: rootParent, height: 100 },
    { blockHash: blockChild, merkleRoot: rootChild, height: 101 },
  ], 102, blockChild);
  const r3 = await request(app).get(`/ready?versionId=${vidChild}`);
  assert.strictEqual(r3.status, 200);
  assert.strictEqual(r3.body.ready, true);

  // 4) Missing envelope on parent -> ready false
  upsertDeclaration(db, { version_id: vidParent, txid: 'p'.repeat(64), type: 'DLM1', status: 'pending', created_at: Math.floor(Date.now()/1000), opret_vout: 0, raw_tx: rawTxParent, proof_json: null } as any);
  const r4 = await request(app).get(`/ready?versionId=${vidChild}`);
  assert.strictEqual(r4.status, 200);
  assert.strictEqual(r4.body.ready, false);
  assert.ok(String(r4.body.reason).startsWith('missing-envelope:'));

  console.log('OK: /ready tests passed.');
})().catch((e) => {
  console.error('ready tests failed:', e);
  process.exit(1);
});
```

3) Update file: package.json (add test script for ready)
With content patch:
```json
{
  "scripts": {
    "test:ready": "ts-node test/integration/ready.spec.ts"
  }
}
```

How to run D04 now
- Set HEADERS_FILE (the tests set it automatically to a temp file).
- Run:
  npm run test:ready

What you’ve completed (matches D04 DoD)
- /ready performs a pure SPV verification per node with live confirmations from headers.json.
- Fails closed on:
  - missing-envelope:<versionId>
  - insufficient-confs (includes current min confirmations)
  - unknown-block-hash (if headers file lacks the block)
- Reorg/height changes are reflected immediately, no pinning of confirmations.

If you want, we can add a CLI verify-ready.ts (calls /ready and exits 0/1) to use in CI pipelines and example preflight scripts.
