) Create file: src/metrics/registry.ts
With content:
```ts
/**
 * Minimal in-memory metrics registry for ops/monitoring.
 * Exposes:
 *  - request counters by route + status class
 *  - admissions counter (/submit)
 *  - bundles cache hits/misses
 *  - SPV proof latency histogram (last N samples) with p50/p95
 *  - uptime
 */

type RouteKey =
  | 'submit'
  | 'bundle'
  | 'ready'
  | 'price'
  | 'data'
  | 'pay'
  | 'advisories'
  | 'producers'
  | 'listings'
  | 'other';

const START_MS = Date.now();
const clamp = (n: number, lo: number, hi: number) => Math.min(Math.max(n, lo), hi);

const reqByRoute: Record<RouteKey, number> = {
  submit: 0,
  bundle: 0,
  ready: 0,
  price: 0,
  data: 0,
  pay: 0,
  advisories: 0,
  producers: 0,
  listings: 0,
  other: 0,
};

const reqByClass: Record<'2xx' | '4xx' | '5xx' | '3xx' | '1xx' | 'other', number> = {
  '1xx': 0,
  '2xx': 0,
  '3xx': 0,
  '4xx': 0,
  '5xx': 0,
  other: 0,
};

let requestsTotal = 0;
let admissionsTotal = 0;

const bundlesCache = { hits: 0, misses: 0 };

// Proof latency reservoir (simple)
const PROOF_SAMPLES_MAX = 512;
const proofLatenciesMs: number[] = [];

// Helpers
function statusClass(code: number): keyof typeof reqByClass {
  if (code >= 100 && code < 200) return '1xx';
  if (code >= 200 && code < 300) return '2xx';
  if (code >= 300 && code < 400) return '3xx';
  if (code >= 400 && code < 500) return '4xx';
  if (code >= 500) return '5xx';
  return 'other';
}

export function incRequest(route: RouteKey, statusCode: number) {
  requestsTotal += 1;
  reqByRoute[route] = (reqByRoute[route] || 0) + 1;
  const sc = statusClass(statusCode);
  reqByClass[sc] = (reqByClass[sc] || 0) + 1;
}

export function incAdmissions(n = 1) {
  admissionsTotal += n;
}

export function cacheHit() {
  bundlesCache.hits += 1;
}

export function cacheMiss() {
  bundlesCache.misses += 1;
}

export function observeProofLatency(ms: number) {
  const v = clamp(ms, 0, 120_000);
  proofLatenciesMs.push(v);
  if (proofLatenciesMs.length > PROOF_SAMPLES_MAX) {
    proofLatenciesMs.shift();
  }
}

function percentile(arr: number[], p: number): number {
  if (!arr.length) return 0;
  const a = arr.slice().sort((x, y) => x - y);
  const idx = Math.floor((p / 100) * (a.length - 1));
  return a[idx];
}

export function snapshotMetrics() {
  const now = Date.now();
  return {
    nowIso: new Date(now).toISOString(),
    uptimeSec: Math.floor((now - START_MS) / 1000),
    requestsTotal,
    requestsByRoute: { ...reqByRoute },
    requestsByClass: { ...reqByClass },
    admissionsTotal,
    bundlesCache: { ...bundlesCache },
    proofLatencyMs: {
      count: proofLatenciesMs.length,
      p50: percentile(proofLatenciesMs, 50),
      p95: percentile(proofLatenciesMs, 95),
      avg:
        proofLatenciesMs.length > 0
          ? Math.round(
              (proofLatenciesMs.reduce((a, b) => a + b, 0) / proofLatenciesMs.length) * 100,
            ) / 100
          : 0,
      max: proofLatenciesMs.length > 0 ? Math.max(...proofLatenciesMs) : 0,
    },
  };
}
```

2) Create file: src/middleware/metrics.ts
With content:
```ts
import { incRequest } from '../metrics/registry';

type RouteKey =
  | 'submit'
  | 'bundle'
  | 'ready'
  | 'price'
  | 'data'
  | 'pay'
  | 'advisories'
  | 'producers'
  | 'listings'
  | 'other';

/**
 * Per-request metrics recorder. Place before the actual route handler.
 */
export function metricsRoute(route: RouteKey) {
  return (req: any, res: any, next: any) => {
    const writeHead = res.writeHead;
    res.writeHead = function patched(this: any, statusCode: number, ...args: any[]) {
      try {
        incRequest(route, statusCode);
      } catch {
        // ignore
      }
      return writeHead.call(this, statusCode, ...args);
    };
    next();
  };
}
```

3) Create file: src/routes/metrics.ts
With content:
```ts
import type { Request, Response, Router } from 'express';
import { Router as makeRouter } from 'express';
 //import fs from 'fs';
import { snapshotMetrics } from '../metrics/registry';
import { getHeadersSnapshot } from '../spv/headers-cache';

const HEADERS_FILE = process.env.HEADERS_FILE || './data/headers.json';

export function opsRouter(db: Database.Database): Router {
  const router = makeRouter();

  router.get('/health', (_req: Request, res: Response) => {
    try {
      // DB ping
      const row = db.prepare('SELECT 1 AS ok').get() as any;
      if (!row || row.ok !== 1) {
        return res.status(500).json({ ok: false, reason: 'db' });
      }
      // Headers file check
      if (!fs.existsSync(HEADERS_FILE)) {
        return res.status(200).json({ ok: true, warn: 'headers-missing' });
      }
      try {
        getHeadersSnapshot(HEADERS_FILE);
      } catch {
        return res.status(200).json({ ok: true, warn: 'headers-unreadable' });
      }
      return res.status(200).json({ ok: true });
    } catch (e: any) {
      return res.status(500).json({ ok: false, reason: String(e?.message || e) });
    }
  });

  router.get('/metrics', (_req: Request, res: Response) => {
    try {
      const m = snapshotMetrics();
      return res.status(200).json(m);
    } catch (e: any) {
      return res.status(500).json({ error: 'metrics-failed', message: String(e?.message || e) });
    }
  });

  return router;
}
```

4) Update file: src/routes/bundle.ts (instrument cache hits/misses and proof latency)
Replace the top imports and add instrumentation inside the handler:
```ts
import type { Request, Response, Router } from 'express';
import { Router as makeRouter } from 'express';
 //import { getDeclarationByVersion, getManifest, getParents } from '../db';
import { verifyEnvelopeAgainstHeaders } from '../spv/verify-envelope';
import { getHeadersSnapshot } from '../spv/headers-cache';
import { bundlesGet, bundlesSet, bundlesInvalidate, bundlesKey } from '../cache/bundles';
import { metricsRoute } from '../middleware/metrics';
import { cacheHit, cacheMiss, observeProofLatency } from '../metrics/registry';

// ... keep existing collectLineage and recomputeConfs...

export function bundleRouter(db: Database.Database): Router {
  const router = makeRouter();

  // record request metrics for bundle route
  router.use('/bundle', metricsRoute('bundle'));

  router.get('/bundle', async (req: Request, res: Response) => {
    try {
      const versionId = String(req.query.versionId || '').toLowerCase();
      if (!/^[0-9a-fA-F]{64}$/.test(versionId)) {
        return res.status(400).json({ error: 'bad-request', hint: 'Provide versionId=64-hex' });
      }
      const depth = Number(req.query.depth || BUNDLE_MAX_DEPTH);
      const key = bundlesKey(versionId, depth);

      // 1) Try cache
      const cached = bundlesGet(key);
      if (cached) {
        cacheHit();
        const body = JSON.parse(JSON.stringify(cached.body));
        const t0 = Date.now();
        const re = await recomputeConfsAndEnforce(body);
        observeProofLatency(Date.now() - t0);
        if (!re.ok) {
          bundlesInvalidate(key);
        } else {
          res.setHeader('x-cache', 'hit');
          return res.status(200).json(body);
        }
      } else {
        cacheMiss();
      }

      // 2) Build fresh
      const { nodes, edges, manifestsArr, proofsArr } = await collectLineage(db, versionId, depth);

      const idx = getHeadersSnapshot(HEADERS_FILE);
      const t1 = Date.now();
      for (const p of proofsArr) {
        const vr = await verifyEnvelopeAgainstHeaders(p.envelope, idx, POLICY_MIN_CONFS);
        if (!vr.ok) {
          return res.status(409).json({ error: 'invalid-envelope', versionId: p.versionId, reason: vr.reason });
        }
        p.envelope.confirmations = vr.confirmations ?? 0;
      }
      observeProofLatency(Date.now() - t1);

      const bundle = {
        bundleType: 'datasetLineageBundle',
        target: versionId,
        graph: { nodes, edges },
        manifests: manifestsArr,
        proofs: proofsArr,
      };

      bundlesSet(key, bundle, true);
      res.setHeader('x-cache', 'miss');
      return res.status(200).json(bundle);
    } catch (e: any) {
      const msg = String(e?.message || e);
      if (msg.startsWith('missing-manifest:') || msg.startsWith('missing-envelope:')) {
        return res.status(409).json({ error: 'incomplete-lineage', hint: msg });
      }
      return res.status(500).json({ error: 'bundle-failed', message: msg });
    }
  });

  return router;
}
```

5) Update file: src/routes/submit-receiver.ts (count admissions)
Add metricsRoute and incAdmissions:
```ts
import { metricsRoute } from '../middleware/metrics';
import { incAdmissions } from '../metrics/registry';

// in factory function:
export function submitReceiverRouter(db: Database.Database, opts: { headersFile?: string; minConfs?: number; bodyMaxSize: number }): Router {
  const router = makeRouter();

  // metrics for submit route
  router.use('/submit', metricsRoute('submit'));

  router.post('/submit', async (req: Request, res: Response) => {
    try {
      // ... existing validation
      incAdmissions(1);
      // ... rest of handler
```

6) Update file: server.ts (mount metrics and per-route metrics middleware)
With content patch:
```ts
import express from 'express';
import { openDb, initSchema } from './src/db';
import { submitDlm1Router } from './src/routes/submit-builder';
import { submitReceiverRouter } from './src/routes/submit-receiver';
import { bundleRouter } from './src/routes/bundle';
import { readyRouter } from './src/routes/ready';
import { priceRouter } from './src/routes/price';
import { listingsRouter } from './src/routes/listings';
import { payRouter } from './src/routes/pay';
import { dataRouter } from './src/routes/data';
import { producersRouter } from './src/routes/producers';
import { advisoriesRouter } from './src/routes/advisories';
import { opsRouter } from './src/routes/metrics';
import { metricsRoute } from './src/middleware/metrics';

const PORT = Number(process.env.OVERLAY_PORT || 8788);
const BODY_MAX_SIZE = Number(process.env.BODY_MAX_SIZE || 1048576);

async function main() {
  const app = express();
  app.use(express.json({ limit: BODY_MAX_SIZE }));

  const db = openDb();
  initSchema(db);

  // Attach per-route metrics wrappers before routers (best-effort)
  app.use('/ready', metricsRoute('ready'));
  app.use('/price', metricsRoute('price'));
  app.use('/v1/data', metricsRoute('data'));
  app.use('/pay', metricsRoute('pay'));
  app.use('/advisories', metricsRoute('advisories'));
  app.use('/producers', metricsRoute('producers'));
  app.use('/listings', metricsRoute('listings'));

  app.use(submitDlm1Router());
  app.use(submitReceiverRouter(db, { bodyMaxSize: BODY_MAX_SIZE }));
  app.use(bundleRouter(db));
  app.use(readyRouter(db));
  app.use(priceRouter(db));
  app.use(payRouter(db));
  app.use(dataRouter(db));
  app.use(listingsRouter(db));
  app.use(producersRouter(db));
  app.use(advisoriesRouter(db));
  app.use(opsRouter(db)); // /health and /metrics

  app.listen(PORT, () => console.log(`Overlay listening on :${PORT}`));
}
main().catch((e) => { console.error(e); process.exit(1); });
```

7) Create file: test/integration/metrics.spec.ts
With content:
```ts
import assert from 'assert';
import express from 'express';
import request from 'supertest';
 //import { initSchema, upsertManifest, upsertDeclaration, replaceEdges } from '../../src/db';
import { bundleRouter } from '../../src/routes/bundle';
import { opsRouter } from '../../src/routes/metrics';
import fs from 'fs';
import os from 'os';
import path from 'path';
import { txidFromRawTx } from '../../src/spv/verify-envelope';

(async function run() {
  // Prepare headers snapshot
  const tmp = fs.mkdtempSync(path.join(os.tmpdir(), 'metrics-'));
  const headersPath = path.join(tmp, 'headers.json');
  process.env.HEADERS_FILE = headersPath;

  // Create simple headers with one block
  const rawTx = '00';
  const txid = txidFromRawTx(rawTx);
  const sib = '11'.repeat(32);
  const crypto = require('crypto') as typeof import('crypto');
  const rev = (b: Buffer) => { const c = Buffer.from(b); c.reverse(); return c; };
  const sha256d = (b: Buffer) => { const a = crypto.createHash('sha256').update(b).digest(); return crypto.createHash('sha256').update(a).digest(); };
  const root = rev(sha256d(Buffer.concat([rev(Buffer.from(txid,'hex')), rev(Buffer.from(sib,'hex'))]))).toString('hex');
  const blockHash = 'f'.repeat(64);
  fs.writeFileSync(headersPath, JSON.stringify({ bestHeight: 100, tipHash: blockHash, byHash: { [blockHash]: { prevHash: '0'.repeat(64), merkleRoot: root, height: 100 } } }, null, 2));

  const app = express();
  app.use(express.json({ limit: '1mb' }));

  const db = new Database(':memory:');
  initSchema(db);

  // Minimal manifest/declaration
  const vid = 'a'.repeat(64);
  const man = { type: 'datasetVersionManifest', datasetId: 'ds', content: { contentHash: 'c'.repeat(64) }, provenance: { createdAt: '2024-01-01T00:00:00Z' }, policy: { license: 'cc-by-4.0', classification: 'public' } };
  upsertManifest(db, { version_id: vid, manifest_hash: vid, content_hash: man.content.contentHash, title: null, license: 'cc-by-4.0', classification: 'public', created_at: man.provenance.createdAt, manifest_json: JSON.stringify(man) });
  replaceEdges(db, vid, []);
  const env = { rawTx, proof: { txid, merkleRoot: root, path: [{ hash: sib, position: 'right' }] }, block: { blockHash, blockHeight: 100 } };
  upsertDeclaration(db, { version_id: vid, txid: 'd'.repeat(64), type: 'DLM1', status: 'pending', created_at: Math.floor(Date.now()/1000), opret_vout: 0, raw_tx: rawTx, proof_json: JSON.stringify(env) } as any);

  app.use(bundleRouter(db));
  app.use(opsRouter(db));

  // Hit /bundle a couple of times to generate metrics + cache hit
  const b1 = await request(app).get(`/bundle?versionId=${vid}`);
  assert.strictEqual(b1.status, 200);
  const b2 = await request(app).get(`/bundle?versionId=${vid}`);
  assert.strictEqual(b2.status, 200);

  // /metrics snapshot should show requests and cache hits >= 1
  const m = await request(app).get('/metrics');
  assert.strictEqual(m.status, 200);
  assert.ok(m.body.requestsTotal >= 2);
  assert.ok(m.body.bundlesCache.hits >= 1 || m.body.bundlesCache.misses >= 1);

  // /health should be ok:true
  const h = await request(app).get('/health');
  assert.strictEqual(h.status, 200);
  assert.strictEqual(h.body.ok, true);

  console.log('OK: /metrics & /health tests passed.');
})().catch((e) => {
  console.error('metrics tests failed:', e);
  process.exit(1);
});
```

8) Update file: package.json (add test script)
With content patch:
```json
{
  "scripts": {
    "test:metrics": "ts-node test/integration/metrics.spec.ts"
  }
}
```

How to run D17
- Start your overlay or run tests:
  npm run test:metrics

What you completed (matches D17 DoD)
- GET /health: checks DB and headers mirror; returns { ok: true } or appropriate warnings.
- GET /metrics: returns structured JSON with:
  - uptime, requestsTotal, per-route and per-status-class counts
  - admissionsTotal (/submit)
  - bundles cache hits/misses
  - SPV proof latency p50/p95/avg/max over recent samples
- Bundle route instruments cache hits/misses and proof verify latency. Submit route counts admissions.

Acceptance
- Take a screenshot of /metrics JSON in your browser/Insomnia.
- Panels can chart requests/second, 4xx/5xx, cache hits, and proof latency.

This keeps ops simple and JSON-first; you can add Prometheus formatting later if needed.