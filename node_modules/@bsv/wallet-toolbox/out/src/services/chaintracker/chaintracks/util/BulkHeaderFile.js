"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.BulkHeaderFiles = exports.BulkHeaderFileStorage = exports.BulkHeaderFileFs = exports.BulkHeaderFile = void 0;
const HeightRange_1 = require("./HeightRange");
const sdk_1 = require("@bsv/sdk");
const WERR_errors_1 = require("../../../../sdk/WERR_errors");
const utilityHelpers_noBuffer_1 = require("../../../../utility/utilityHelpers.noBuffer");
class BulkHeaderFile {
    constructor(info) {
        this.chain = info.chain;
        this.count = info.count;
        this.data = info.data;
        this.fileHash = info.fileHash;
        this.fileId = info.fileId;
        this.fileName = info.fileName;
        this.firstHeight = info.firstHeight;
        this.lastChainWork = info.lastChainWork;
        this.lastHash = info.lastHash;
        this.prevChainWork = info.prevChainWork;
        this.prevHash = info.prevHash;
        this.sourceUrl = info.sourceUrl;
        this.validated = info.validated;
    }
    get heightRange() {
        return new HeightRange_1.HeightRange(this.firstHeight, this.firstHeight + this.count - 1);
    }
    async ensureData() {
        if (!this.data)
            throw new WERR_errors_1.WERR_INVALID_OPERATION(`data is undefined and no ensureData() override`);
        return this.data;
    }
    /**
     * Whenever reloading data from a backing store, validated fileHash must be re-verified
     * @returns the sha256 hash of the file's data as base64 string.
     */
    async computeFileHash() {
        if (!this.data)
            throw new WERR_errors_1.WERR_INVALID_OPERATION(`requires defined data`);
        return (0, utilityHelpers_noBuffer_1.asString)(sdk_1.Hash.sha256((0, utilityHelpers_noBuffer_1.asArray)(this.data)), 'base64');
    }
    async releaseData() {
        this.data = undefined;
    }
    toCdnInfo() {
        return {
            count: this.count,
            fileHash: this.fileHash,
            fileName: this.fileName,
            firstHeight: this.firstHeight,
            lastChainWork: this.lastChainWork,
            lastHash: this.lastHash,
            prevChainWork: this.prevChainWork,
            prevHash: this.prevHash
        };
    }
    toStorageInfo() {
        return {
            count: this.count,
            fileHash: this.fileHash,
            fileName: this.fileName,
            firstHeight: this.firstHeight,
            lastChainWork: this.lastChainWork,
            lastHash: this.lastHash,
            prevChainWork: this.prevChainWork,
            prevHash: this.prevHash,
            chain: this.chain,
            validated: this.validated,
            sourceUrl: this.sourceUrl,
            fileId: this.fileId
        };
    }
}
exports.BulkHeaderFile = BulkHeaderFile;
class BulkHeaderFileFs extends BulkHeaderFile {
    constructor(info, fs, rootFolder) {
        super(info);
        this.fs = fs;
        this.rootFolder = rootFolder;
    }
    async readDataFromFile(length, offset) {
        if (this.data) {
            return this.data.slice(offset, offset + length);
        }
        const f = await this.fs.openReadableFile(this.fs.pathJoin(this.rootFolder, this.fileName));
        try {
            const buffer = await f.read(length, offset);
            return buffer;
        }
        finally {
            await f.close();
        }
    }
    async ensureData() {
        if (this.data)
            return this.data;
        this.data = await this.readDataFromFile(this.count * 80, 0);
        if (!this.data)
            throw new WERR_errors_1.WERR_INVALID_OPERATION(`failed to read data for ${this.fileName}`);
        if (this.validated) {
            const hash = await this.computeFileHash();
            if (hash !== this.fileHash)
                throw new WERR_errors_1.WERR_INVALID_OPERATION(`BACKING FILE DATA CORRUPTION: invalid fileHash for ${this.fileName}`);
        }
        return this.data;
    }
}
exports.BulkHeaderFileFs = BulkHeaderFileFs;
class BulkHeaderFileStorage extends BulkHeaderFile {
    constructor(info, storage, fetch) {
        super(info);
        this.storage = storage;
        this.fetch = fetch;
    }
    async readDataFromFile(length, offset) {
        return (await this.ensureData()).slice(offset, offset + length);
    }
    async ensureData() {
        if (this.data)
            return this.data;
        if (!this.sourceUrl || !this.fetch) {
            throw new WERR_errors_1.WERR_INVALID_PARAMETER('sourceUrl and fetch', 'defined. Or data must be defined.');
        }
        const url = this.fetch.pathJoin(this.sourceUrl, this.fileName);
        this.data = await this.fetch.download(url);
        if (!this.data)
            throw new WERR_errors_1.WERR_INVALID_OPERATION(`failed to download data from ${url}`);
        if (this.validated) {
            const hash = await this.computeFileHash();
            if (hash !== this.fileHash)
                throw new WERR_errors_1.WERR_INVALID_OPERATION(`BACKING DOWNLOAD DATA CORRUPTION: invalid fileHash for ${this.fileName}`);
        }
        return this.data;
    }
}
exports.BulkHeaderFileStorage = BulkHeaderFileStorage;
class BulkHeaderFiles {
    constructor(rootFolder, jsonFilename, files, headersPerFile) {
        this.rootFolder = rootFolder;
        this.jsonFilename = jsonFilename;
        this.files = files;
        this.headersPerFile = headersPerFile;
    }
}
exports.BulkHeaderFiles = BulkHeaderFiles;
//# sourceMappingURL=BulkHeaderFile.js.map